{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Feature Extraction from Texts\n","</font></b></h1>"],"metadata":{"id":"g30UjW7xCnPy"}},{"cell_type":"markdown","source":["<h2>\n","<b>\n","\n","<ul>\n","<font color = 'brown green'>\n","\n","<li>\n","Machine learning algorithms do not understand textual data directly.\n","</li><br>\n","\n","<li>\n","We need to represent the text data in numerical form or vectors.\n","</li><br>\n","\n","<li>\n","To convert each textual sentence into a vector, we need to represent it as a set of features.\n","</li><br>\n","\n","<li>\n","This set of features should uniquely represent the text, though, individually, some of the features may be common across many textual sentences.\n","</li><br>\n","\n","<li>\n","Features can be classified into two different categories:\n","</li><br>\n","\n","<li>\n","General features: These features are statistical calculations and do not depend\n","on the content of the text. Some examples of general features could be the\n","number of tokens in the text, the number of characters in the text, and so on.\n","</li><br>\n","\n","<li>\n","Specific features: These features are dependent on the inherent meaning of\n","the text and represent the semantics of the text. For example, the frequency of\n","unique words in the text is a specific feature.\n","</li><br>\n","\n","</font>\n","</ul>\n","</b>\n","</h2>"],"metadata":{"id":"0uclDav8wec7"}},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Extracting General Features from Raw Text\n","</font></b></h1>"],"metadata":{"id":"LQmnWWAOi3Zx"}},{"cell_type":"markdown","source":["<h2>\n","<b>\n","\n","<ul>\n","<font color = 'brown green'>\n","\n","<li>\n","As we've already learned, general features refer to those that are not directly\n","dependent on the individual tokens constituting a text corpus.\n","</li><br>\n","\n","<li>\n","Let's consider these two sentences: \"The sky is blue\" and \"The pillar is yellow\".\n","</li><br>\n","\n","<li>\n","Here, the sentences have the same number of words (a general feature)—that is, four.\n","</li><br>\n","\n","<li>\n","But the individual constituent tokens are different.\n","</li><br>\n","\n","<li>\n","Let's complete an exercise to understand this better.\n","</li><br>\n","\n","</font>\n","</ul>\n","</b>\n","</h2>"],"metadata":{"id":"5RnPixbjjG8K"}},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Exercise 01: Extracting General Features from Raw Text\n","</font></b></h1>"],"metadata":{"id":"j328a7jDdrJ5"}},{"cell_type":"markdown","source":["In this exercise, we will extract general features from input text. These general features include detecting the number of words, the presence of \"wh\" words (words beginning with \"wh\", such as \"what\" and \"why\") and the language in which the text is written."],"metadata":{"id":"XS32RFyid6ZD"}},{"cell_type":"markdown","source":["1. Open a Jupyter Notebook."],"metadata":{"id":"od4591ujeEQm"}},{"cell_type":"markdown","source":["2. Import the **pandas** library and create a DataFrame with four sentences."],"metadata":{"id":"hF2kJdXyeFmr"}},{"cell_type":"code","source":["import pandas as pd\n","from textblob import TextBlob\n","\n","import nltk\n","nltk.download('punkt')  "],"metadata":{"id":"nZinGX8Ti8DJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673662071747,"user_tz":-300,"elapsed":2099,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"9eae4e5d-896c-4913-f5a9-9e7502401f81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["df = pd.DataFrame([['The interim budget for 2019 will be announced on 1st February.'], ['Do you know how much expectation the middle-class working population is having from this budget?'], ['February is the shortest month in a year.'], ['This financial year will end on 31st March.']])\n","df.columns = ['text']\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"RC9txwuYfW4Y","executionInfo":{"status":"ok","timestamp":1673662089201,"user_tz":-300,"elapsed":405,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"cbd36c4b-b835-401a-ff38-1eaaef9af219"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text\n","0  The interim budget for 2019 will be announced ...\n","1  Do you know how much expectation the middle-cl...\n","2          February is the shortest month in a year.\n","3        This financial year will end on 31st March."],"text/html":["\n","  <div id=\"df-c05f7509-b20b-4faf-aa2b-341826df1f7b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>The interim budget for 2019 will be announced ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Do you know how much expectation the middle-cl...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>February is the shortest month in a year.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>This financial year will end on 31st March.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c05f7509-b20b-4faf-aa2b-341826df1f7b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c05f7509-b20b-4faf-aa2b-341826df1f7b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c05f7509-b20b-4faf-aa2b-341826df1f7b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["3. Use the **apply()** function to iterate through each row of the column text,\n","convert them into **TextBlob** objects, and extract words from them."],"metadata":{"id":"0h2QbstaeM3M"}},{"cell_type":"code","source":["def add_num_words(df):\n","    df['number_of_words'] = df['text'].apply(lambda x : len(TextBlob(str(x)).words))\n","    return df"],"metadata":{"id":"tyxuL9Rng3FX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["add_num_words(df) ['number_of_words']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dna5Wp07CZeQ","executionInfo":{"status":"ok","timestamp":1673662151747,"user_tz":-300,"elapsed":13,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"44d8cc63-4ab6-445c-fc8f-3f0b3cbebc0f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    11\n","1    15\n","2     8\n","3     8\n","Name: number_of_words, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["4. Use the **apply()** function to iterate through each row of the column text,\n","convert the text into **TextBlob** objects, and extract the words from them\n","to check whether any of them belong to the list of \"wh\" words that has been\n","declared."],"metadata":{"id":"IczhMJAMefDD"}},{"cell_type":"code","source":["def is_present(wh_words, df):\n"," \n","    # The below line of code will find the intersection between set of tokens of\n","    #  every sentence and the wh_words and will return true if the length of intersection\n","    #  set is non-zero.\n","    df['is_wh_words_present'] = df['text'].apply(lambda x : True if \\\n","                                                 len(set(TextBlob(str(x)).words).intersection(wh_words))>0 else False)\n","    return df\n","\n","wh_words = set(['why', 'who', 'which', 'what', 'where', 'when', 'how'])\n","\n","is_present(wh_words, df)['is_wh_words_present']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ck-tBLnJevOw","executionInfo":{"status":"ok","timestamp":1673662185788,"user_tz":-300,"elapsed":365,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"0604c9de-d240-467b-f61d-8be5d9f2dc81"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    False\n","1     True\n","2    False\n","3    False\n","Name: is_wh_words_present, dtype: bool"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Exercise 02: Exercise 2.12: Extracting General Features from Text\n","</font></b></h1>"],"metadata":{"id":"WGTjDBA8vyxn"}},{"cell_type":"markdown","source":["In this exercise, we will extract various general features from documents. \n","<br>The dataset that we will be using here consists of random statements.\n","<br>Our objective is to find the frequency of various general features such as punctuation, uppercase and lowercase words, letters, digits, words, and whitespaces."],"metadata":{"id":"xdoPLBHBv6vz"}},{"cell_type":"markdown","source":["1. Open a Jupyter Notebook."],"metadata":{"id":"anLq1QKExAuy"}},{"cell_type":"markdown","source":["2. Insert a new cell and add the following code to import the necessary libraries:"],"metadata":{"id":"HeMMy25CxDPT"}},{"cell_type":"code","source":["import pandas as pd\n","from string import punctuation\n","import nltk\n","nltk.download('tagsets')\n","nltk.download('punkt')\n","from nltk.data import load\n","nltk.download('averaged_perceptron_tagger')\n","from nltk import pos_tag\n","from nltk import word_tokenize\n","from collections import Counter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ky53czhXv5iH","executionInfo":{"status":"ok","timestamp":1674368459820,"user_tz":-300,"elapsed":3894,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"6b4e54ba-4626-4959-ded8-a91e7916fa74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package tagsets to /root/nltk_data...\n","[nltk_data]   Unzipping help/tagsets.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]}]},{"cell_type":"markdown","source":["3. To see what different kinds of parts of speech **nltk** provides, add the\n","following code:"],"metadata":{"id":"0GxBBtdoxHi6"}},{"cell_type":"code","source":["def get_tagsets():\n","  tagdict = load('help/tagsets/upenn_tagset.pickle')\n","  return list(tagdict.keys())\n","  \n","tag_list = get_tagsets()\n","print(tag_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JHfgw2XxOBI","executionInfo":{"status":"ok","timestamp":1674368463071,"user_tz":-300,"elapsed":12,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"99eb1de0-5c16-4be8-97da-b1816f2d7d4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['LS', 'TO', 'VBN', \"''\", 'WP', 'UH', 'VBG', 'JJ', 'VBZ', '--', 'VBP', 'NN', 'DT', 'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '.', ',', '``', '$', 'RB', 'RBR', 'RBS', 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS']\n"]}]},{"cell_type":"markdown","source":["4. Calculate the number of occurrences of each **PoS** by iterating through each\n","document and annotating each word with the corresponding pos tag. Add the\n","following code to implement this:"],"metadata":{"id":"13K4uhnexPOk"}},{"cell_type":"code","source":["def  get_pos_occurrence_freq(data, tag_list):\n","  \n","  # get list of sentences in text_list\n","  text_list = data.text\n","\n","  # create empty dataframe\n","  feature_df = pd.DataFrame(columns = tag_list)\n","  for text_line in text_list:\n","\n","    # get pos tags of each word\n","    pos_tags = [j for i, j in pos_tag(word_tokenize(text_line))]\n","\n","    # create a dict of pos tags and their frequency in given sentence.\n","    row = dict(Counter(pos_tags))\n","    feature_df = feature_df.append(row, ignore_index = True)\n","  feature_df.fillna(0, inplace = True)\n","\n","  return feature_df\n","\n","tag_list = get_tagsets()\n","\n","data = pd.read_csv('/content/drive/MyDrive/NLP/Feature Extraction Methods in NLP/data.csv')\n","feature_df = get_pos_occurrence_freq(data, tag_list)\n","feature_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"wSnsPfVwxZJn","executionInfo":{"status":"ok","timestamp":1674368467817,"user_tz":-300,"elapsed":1455,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"6ac318b9-18cc-4042-f42a-8f559e89daa8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    LS   TO  VBN   ''   WP   UH  VBG   JJ  VBZ   --  ...   MD   VB  WRB  NNP  \\\n","0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n","3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0  0.0   \n","\n","    EX  NNS  SYM   CC   CD  POS  \n","0  0.0  1.0  0.0  0.0  0.0  0.0  \n","1  0.0  1.0  0.0  0.0  0.0  0.0  \n","2  0.0  0.0  0.0  0.0  0.0  0.0  \n","3  0.0  0.0  0.0  0.0  0.0  0.0  \n","4  0.0  0.0  0.0  0.0  0.0  0.0  \n","\n","[5 rows x 45 columns]"],"text/html":["\n","  <div id=\"df-562eaeb4-1195-4e6a-9572-75a9cc1e8172\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LS</th>\n","      <th>TO</th>\n","      <th>VBN</th>\n","      <th>''</th>\n","      <th>WP</th>\n","      <th>UH</th>\n","      <th>VBG</th>\n","      <th>JJ</th>\n","      <th>VBZ</th>\n","      <th>--</th>\n","      <th>...</th>\n","      <th>MD</th>\n","      <th>VB</th>\n","      <th>WRB</th>\n","      <th>NNP</th>\n","      <th>EX</th>\n","      <th>NNS</th>\n","      <th>SYM</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>POS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 45 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-562eaeb4-1195-4e6a-9572-75a9cc1e8172')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-562eaeb4-1195-4e6a-9572-75a9cc1e8172 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-562eaeb4-1195-4e6a-9572-75a9cc1e8172');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["5. To calculate the number of punctuation marks, add the following code:"],"metadata":{"id":"THuQdkZaxZsr"}},{"cell_type":"code","source":["def add_punctuation_count(feature_df, data):\n","\n","  feature_df['num_of_unique_punctuations'] = data['text'].apply(lambda x: len(set(x).intersection(set(punctuation))))\n","  \n","  return feature_df  \n","\n","feature_df = add_punctuation_count(feature_df, data)\n","\n","feature_df['num_of_unique_punctuations'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gY-3d65pxgk8","executionInfo":{"status":"ok","timestamp":1674368470988,"user_tz":-300,"elapsed":12,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"1e762001-5160-4c56-8094-f88561938314"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0\n","1    0\n","2    1\n","3    1\n","4    0\n","Name: num_of_unique_punctuations, dtype: int64"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["6. To calculate the number of capitalized words, add the following code:"],"metadata":{"id":"g5P3RHPMxiag"}},{"cell_type":"code","source":["def get_captalized_word_count(feature_df, data):\n","\n","  feature_df['number_of_captalized_words'] = data['text'].apply(lambda x: len([word for word in word_tokenize(str(x)) if word[0].isupper()]))\n","\n","  return feature_df\n","\n","feature_df = get_captalized_word_count(feature_df, data)\n","\n","feature_df['number_of_captalized_words'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eLRWNvvkxpCV","executionInfo":{"status":"ok","timestamp":1674368646896,"user_tz":-300,"elapsed":6,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"5a0ba875-698d-4910-8b22-cb47c0b0b111"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    1\n","1    1\n","2    1\n","3    1\n","4    1\n","Name: number_of_captalized_words, dtype: int64"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["7. To calculate the number of lowercase words, add the following code:"],"metadata":{"id":"uYe7xrAWxpmP"}},{"cell_type":"code","source":["def get_small_word_count(feature_df, data):\n","\n","  feature_df['number_of_small_words'] = data['text'].apply(lambda x: len([word for word in word_tokenize(str(x)) if word[0].islower()]))\n","  \n","  return feature_df\n","\n","feature_df = get_small_word_count(feature_df, data)\n","feature_df['number_of_small_words'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8m6Ab_QIxvHh","executionInfo":{"status":"ok","timestamp":1674369338293,"user_tz":-300,"elapsed":777,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"c6058517-349f-47ff-d345-fdb75c20368c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    4\n","1    3\n","2    7\n","3    3\n","4    2\n","Name: number_of_small_words, dtype: int64"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["8. To calculate the number of letters in the DataFrame, use the following code:"],"metadata":{"id":"P_Ol8gBwxvqQ"}},{"cell_type":"code","source":["def get_number_of_alphabets(feature_df, data):\n","\n","  feature_df['number_of_alphabets'] = data['text'].apply(lambda x: len([ch for ch in str(x) if ch.isalpha()]))\n","\n","  return feature_df\n","\n","feature_df = get_number_of_alphabets(feature_df, data)\n","feature_df['number_of_alphabets'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lxiaHLArypaU","executionInfo":{"status":"ok","timestamp":1674370095199,"user_tz":-300,"elapsed":8,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"11d38d22-9249-4d3c-e44f-f335a0d30e80"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    19\n","1    18\n","2    28\n","3    14\n","4    13\n","Name: number_of_alphabets, dtype: int64"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["9. To calculate the number of digits in the DataFrame, add the following code:"],"metadata":{"id":"PG1AXapmyqnk"}},{"cell_type":"code","source":["def get_number_of_digit_count(feature_df, data):\n","\n","  feature_df['number_of_digits'] = data['text'].apply(lambda x: len([ch for ch in str(x) if ch.isdigit()]))\n","\n","  return feature_df\n","\n","feature_df = get_number_of_digit_count(feature_df, data)\n","feature_df['number_of_digits'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gRXpdDTgyw0T","executionInfo":{"status":"ok","timestamp":1674370871751,"user_tz":-300,"elapsed":11,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"b3512c5b-14f9-4d24-c040-847cca9e3986"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","Name: number_of_digits, dtype: int64"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["10. To calculate the number of words in the DataFrame, add the following code:"],"metadata":{"id":"nPB_fjAMy1p1"}},{"cell_type":"code","source":["def get_number_of_words(feature_df, data):\n","\n","  feature_df['number_of_words'] = data['text'].apply(lambda x: len(word_tokenize(str(x))))\n","\n","  return feature_df\n","\n","feature_df = get_number_of_words(feature_df, data)\n","feature_df['number_of_words'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Hj7AfUXy2Tc","executionInfo":{"status":"ok","timestamp":1674371151732,"user_tz":-300,"elapsed":7,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"94b8360a-768d-41c4-fa9f-4a6da219aa9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    5\n","1    4\n","2    9\n","3    5\n","4    3\n","Name: number_of_words, dtype: int64"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","source":["11. To calculate the number of whitespaces in the DataFrame, add the\n","following code:"],"metadata":{"id":"4rE3iNDky6to"}},{"cell_type":"code","source":["def get_number_of_whitespaces(feature_df, data):\n","\n","  feature_df['number_of_whitespaces'] = data['text'].apply(lambda x: len([ch for ch in str(x) if ch.isspace()]))\n","\n","  return feature_df\n","\n","feature_df = get_number_of_whitespaces(feature_df, data)\n","feature_df['number_of_whitespaces'].head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVqZc3oay7kO","executionInfo":{"status":"ok","timestamp":1674371599146,"user_tz":-300,"elapsed":18,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"ed35c46a-272b-429b-a9f7-05acbd9f48d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    4\n","1    3\n","2    7\n","3    3\n","4    2\n","Name: number_of_whitespaces, dtype: int64"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","source":["12. To view the full feature set we have just created, add the following code:"],"metadata":{"id":"BRsjJTjRzCXv"}},{"cell_type":"code","source":["feature_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":300},"id":"Vx3YE43izDFd","executionInfo":{"status":"ok","timestamp":1674371650122,"user_tz":-300,"elapsed":39,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"8869b0bd-087a-40b7-91c7-b657728f1758"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    LS   TO  VBN   ''   WP   UH  VBG   JJ  VBZ   --  ...   CC   CD  POS  \\\n","0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n","1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n","2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n","3  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n","4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  ...  0.0  0.0  0.0   \n","\n","   num_of_unique_punctuations  number_of_captalized_words  \\\n","0                           0                           1   \n","1                           0                           1   \n","2                           1                           1   \n","3                           1                           1   \n","4                           0                           1   \n","\n","   number_of_small_words  number_of_alphabets  number_of_digits  \\\n","0                      4                   19                 0   \n","1                      3                   18                 0   \n","2                      7                   28                 0   \n","3                      3                   14                 0   \n","4                      2                   13                 0   \n","\n","   number_of_words  number_of_whitespaces  \n","0                5                      4  \n","1                4                      3  \n","2                9                      7  \n","3                5                      3  \n","4                3                      2  \n","\n","[5 rows x 52 columns]"],"text/html":["\n","  <div id=\"df-5dcbbe4c-02fe-435c-a8c5-917f2f9bf175\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LS</th>\n","      <th>TO</th>\n","      <th>VBN</th>\n","      <th>''</th>\n","      <th>WP</th>\n","      <th>UH</th>\n","      <th>VBG</th>\n","      <th>JJ</th>\n","      <th>VBZ</th>\n","      <th>--</th>\n","      <th>...</th>\n","      <th>CC</th>\n","      <th>CD</th>\n","      <th>POS</th>\n","      <th>num_of_unique_punctuations</th>\n","      <th>number_of_captalized_words</th>\n","      <th>number_of_small_words</th>\n","      <th>number_of_alphabets</th>\n","      <th>number_of_digits</th>\n","      <th>number_of_words</th>\n","      <th>number_of_whitespaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>19</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>28</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 52 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5dcbbe4c-02fe-435c-a8c5-917f2f9bf175')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5dcbbe4c-02fe-435c-a8c5-917f2f9bf175 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5dcbbe4c-02fe-435c-a8c5-917f2f9bf175');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":34}]}]}