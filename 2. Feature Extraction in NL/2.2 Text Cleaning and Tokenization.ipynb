{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Cleaning Text Data\n","</font></b></h1>"],"metadata":{"id":"g30UjW7xCnPy"}},{"cell_type":"markdown","source":["<h2>\n","<b>\n","\n","<ul>\n","<font color = 'brown green'>\n","\n","<li>\n","The text data that we are going to discuss here is unstructured text data, which\n","consists of written sentences.\n","</li><br>\n","\n","<li>\n","Most of the time, this text data cannot be used as it is for analysis because it contains some noisy elements, that is, elements that do not really contribute much to the meaning of the sentence at all.\n","</li><br>\n","\n","<li>\n","These noisy elements need to be removed because they do not contribute to the meaning and semantics of the text.\n","</li><br>\n","\n","<li>\n","If they are not removed, they can not only waste system memory and processing time, but also negatively impact the accuracy of the results.\n","</li><br>\n","\n","<li>\n","Data cleaning is the art of extracting meaningful portions from data by eliminating unnecessary details.\n","</li><br>\n","\n","<li>\n","Consider the sentence, \"He tweeted, <i> 'Live coverage of General Elections\n","available at this.tv/show/ge2019. _/\\_ Please tune in :) '. \"</i>\n","</li><br>\n","\n","<li>\n","In this example, to perform NLP tasks on the sentence, we will need to remove the emojis, punctuation, and stop words, and then change the words into their base grammatical form.\n","</li><br>\n","\n","<li>\n","To achieve this, methods such as stopword removal, tokenization, and stemming are used.\n","</li><br>\n","\n","<li>\n","Before we do so, let's get acquainted with some basic NLP libraries that we will be using here:\n","\n","<ul>\n","<font color = 'red'>\n","<li>\n","Re:<br>\n","This is a standard Python library that's used for string searching and string\n","manipulation. It contains methods such as match(), search(), findall(), split(), and sub(), which are used for basic string matching, searching, replacing, and more, using regular expressions.\n","<br> A regular expression is nothing but a set of characters in a specific order that represents a pattern. This pattern is searched for in the texts.\n","</li><br>\n","\n","<li>\n","textblob:<br>\n","This is an open source Python library that provides different methods for performing various NLP tasks such as tokenization and PoS tagging. It is similar to nltk.\n","It is built on the top of nltk and is much simpler as it has an easier to use interface and excellent documentation. In projects that don't involve a lot of complexity, it should be preferable to nltk.\n","</li><br>\n","\n","<li>\n","keras:<br>\n","This is an open source, high-level neural network library that's was\n","developed on top of another neural network library called TensorFlow.<br>\n","In addition to neural network functionality, it also provides methods for basic text processing and NLP tasks.\n","</li>\n","\n","</font>\n","</ul>\n","\n","</li><br>\n","\n","</ul>\n","</b>\n","</h2>"],"metadata":{"id":"-0CaUy_wDA2e"}},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Tokenization\n","</font></b></h1>"],"metadata":{"id":"H7Ny92IXwRaG"}},{"cell_type":"markdown","source":["<h2>\n","<b>\n","\n","<ul>\n","<font color = 'brown green'>\n","\n","<li>\n","Tokenization is the process of splitting sentences into their constituents; that is, words and punctuation.\n","</li><br>\n","\n","<li>\n","Let's perform a simple exercise to see how this can be done using various packages.\n","</li>\n","\n","</font>\n","</ul>\n","</b>\n","</h2>"],"metadata":{"id":"0uclDav8wec7"}},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Exercise 1: Text Cleaning and Tokenization\n","</font></b></h1>"],"metadata":{"id":"WHRMc2xYxdDk"}},{"cell_type":"markdown","source":["In this exercise, we will clean some text and extract the tokens from it. Follow these steps to complete this exercise:"],"metadata":{"id":"4fkBXeuGxaHu"}},{"cell_type":"markdown","source":["1. Open a Jupyter Notebook."],"metadata":{"id":"aYxoeOtSxvO4"}},{"cell_type":"markdown","source":["2. Import the **re** package:"],"metadata":{"id":"84A6f-YexxTa"}},{"cell_type":"code","source":["import re"],"metadata":{"id":"QWhtFudNLdw3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Create a method called **clean_text()** that will delete all characters other\n","than digits, alphabetical characters, and whitespaces from the text and split\n","the text into tokens. For this, we will use the text which matches with all\n","non-alphanumeric characters, and we will replace all of them with an\n","empty string:"],"metadata":{"id":"VuDfdbSix38u"}},{"cell_type":"code","source":["def clean_text(sentence):\n","  return re.sub(r'([^\\s\\w]|_)+', ' ', sentence).split()"],"metadata":{"id":"kBDL9CfMyGxs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Store the sentence to be cleaned in a variable named **sentence** and pass it\n","through the preceding function."],"metadata":{"id":"jH9JX0LcyHpP"}},{"cell_type":"code","source":["sentence = 'Sunil tweeted, \"Witnessing 70th Republic Day \"\\\n","           \"of India from Rajpath, New Delhi. \"\\\n","           \"Mesmerizing performance by Indian Army! \"\\\n","           \"Awesome airshow! @india_official \"\\\n","           \"@indian_army #India #70thRepublic_Day. \"\\\n","           \"For more photos ping me sunil@photoking.com :)\"'"],"metadata":{"id":"dU0I2MAByR6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["clean_text(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P4FVw_HS1ZYS","executionInfo":{"status":"ok","timestamp":1672205957836,"user_tz":-300,"elapsed":13,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"5aea16ad-d388-4b0f-aef1-06e230d42d4f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Sunil',\n"," 'tweeted',\n"," 'Witnessing',\n"," '70th',\n"," 'Republic',\n"," 'Day',\n"," 'of',\n"," 'India',\n"," 'from',\n"," 'Rajpath',\n"," 'New',\n"," 'Delhi',\n"," 'Mesmerizing',\n"," 'performance',\n"," 'by',\n"," 'Indian',\n"," 'Army',\n"," 'Awesome',\n"," 'airshow',\n"," 'india',\n"," 'official',\n"," 'indian',\n"," 'army',\n"," 'India',\n"," '70thRepublic',\n"," 'Day',\n"," 'For',\n"," 'more',\n"," 'photos',\n"," 'ping',\n"," 'me',\n"," 'sunil',\n"," 'photoking',\n"," 'com']"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","n-grams\n","</font></b></h1>"],"metadata":{"id":"4LQ8QxrN6P9-"}},{"cell_type":"markdown","source":["<h2>\n","<b>\n","\n","<ul>\n","<font color = 'brown green'>\n","\n","<li>\n","Often, extracting each token separately does not help.\n","</li><br>\n","\n","<li>\n","For instance, consider the sentence, \"I don't hate you, but your behavior.\"\n","</li><br>\n","\n","<li>\n","Here, if we process each of the tokens, such as \"hate\" and \"behavior,\" separately, then the true meaning of the sentence would not be comprehended.\n","</li><br>\n","\n","<li>\n","In this case, the context in which these tokens are present becomes\n","essential.\n","</li><br>\n","\n","<li>\n","Thus, we consider n consecutive tokens at a time. n-grams refers to the\n","grouping of n consecutive tokens together.\n","</li><br>\n","\n","</font>\n","</ul>\n","</b>\n","</h2>"],"metadata":{"id":"WQK0Jpeu6Yks"}},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Exercise 2: Extracting n-grams\n","</font></b></h1>"],"metadata":{"id":"UhuUkEN8Cnh1"}},{"cell_type":"markdown","source":["In this exercise, we will extract **n-grams** using three different methods. First, we will use **custom-defined functions**, and then the **nltk** and **textblob** libraries. Follow these steps to complete this exercise:"],"metadata":{"id":"nH8eWTo7C_U-"}},{"cell_type":"markdown","source":["1. Open a Jupyter Notebook."],"metadata":{"id":"RAxOLrt2DX80"}},{"cell_type":"markdown","source":["2. Import the **re** package and create a custom-defined function, which we can use to extract **n**-grams"],"metadata":{"id":"54SAC1TzE8P_"}},{"cell_type":"code","source":["import re\n","\n","def n_gram_extractor(sentence, n):\n","  tokens = re.sub(r'([^\\s\\w]|_)+', ' ', sentence).split()\n","  for i in range(len(tokens) - n + 1):\n","    print(tokens[i:i+n])"],"metadata":{"id":"SNUG-RLMFHZu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. If **n** is 2, two consecutive tokens will be taken, resulting in **bigrams**. To check the bigrams, we pass the function the text and with **n=2**."],"metadata":{"id":"4h7yac_aExos"}},{"cell_type":"code","source":["n_gram_extractor('The cute little boy is playing with the kitten.', 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugP9c1581fWV","executionInfo":{"status":"ok","timestamp":1672204709984,"user_tz":-300,"elapsed":607,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"641fd5a1-1d92-43ce-c0cd-6a209108d4a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'cute']\n","['cute', 'little']\n","['little', 'boy']\n","['boy', 'is']\n","['is', 'playing']\n","['playing', 'with']\n","['with', 'the']\n","['the', 'kitten']\n"]}]},{"cell_type":"markdown","source":["4. To check the trigrams, we pass the function with the text and with **n**=3."],"metadata":{"id":"cSPebEEfFR1b"}},{"cell_type":"code","source":["n_gram_extractor('The cute little boy is playing with the kitten.', 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kRrgl_ULFYAs","executionInfo":{"status":"ok","timestamp":1672204803554,"user_tz":-300,"elapsed":1001,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"0cfde8e2-cb43-4d2a-b84d-99757252b702"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['The', 'cute', 'little']\n","['cute', 'little', 'boy']\n","['little', 'boy', 'is']\n","['boy', 'is', 'playing']\n","['is', 'playing', 'with']\n","['playing', 'with', 'the']\n","['with', 'the', 'kitten']\n"]}]},{"cell_type":"markdown","source":["5. To check the bigrams using the **nltk** library, add the following code:"],"metadata":{"id":"jkCOXfhdFYm6"}},{"cell_type":"code","source":["from nltk import ngrams\n","\n","list(ngrams('The cute little boy is playing with the kitten.'.split(), 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e94-1tzTFgGn","executionInfo":{"status":"ok","timestamp":1672205031040,"user_tz":-300,"elapsed":641,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"5877d12b-6e64-4a8a-a948-7d04cf827afa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('The', 'cute'),\n"," ('cute', 'little'),\n"," ('little', 'boy'),\n"," ('boy', 'is'),\n"," ('is', 'playing'),\n"," ('playing', 'with'),\n"," ('with', 'the'),\n"," ('the', 'kitten.')]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["6. To check the **trigrams** using the **nltk** library, add the following code:"],"metadata":{"id":"oqzdUTteFguN"}},{"cell_type":"code","source":["list(ngrams('The cute little boy is playing with the kitten.'.split(), 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7pv9MNl-FqQ_","executionInfo":{"status":"ok","timestamp":1672205122363,"user_tz":-300,"elapsed":1220,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"8a305949-53d7-4745-d2e5-a58499e7a1f2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('The', 'cute', 'little'),\n"," ('cute', 'little', 'boy'),\n"," ('little', 'boy', 'is'),\n"," ('boy', 'is', 'playing'),\n"," ('is', 'playing', 'with'),\n"," ('playing', 'with', 'the'),\n"," ('with', 'the', 'kitten.')]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["7. To check the bigrams using the **textblob** library, add the following code:"],"metadata":{"id":"oaF2wTmLFq5L"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xViFmdgjNrA7","executionInfo":{"status":"ok","timestamp":1672205531118,"user_tz":-300,"elapsed":1098,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"2259390e-bf0f-46f5-8baa-190fd716f063"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["from textblob import TextBlob\n","\n","blob = TextBlob('The cute little boy is playing with the kitten.')\n","blob.ngrams(n = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WR-sKa47F34J","executionInfo":{"status":"ok","timestamp":1672205533138,"user_tz":-300,"elapsed":15,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"32ec8570-1403-470f-bf00-70751bf0e403"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[WordList(['The', 'cute']),\n"," WordList(['cute', 'little']),\n"," WordList(['little', 'boy']),\n"," WordList(['boy', 'is']),\n"," WordList(['is', 'playing']),\n"," WordList(['playing', 'with']),\n"," WordList(['with', 'the']),\n"," WordList(['the', 'kitten'])]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["8. To check the trigrams using the **textblob** library, add the following code:"],"metadata":{"id":"uE9qxxNdF-Nv"}},{"cell_type":"code","source":["blob.ngrams(n = 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eyvb4svwGA7i","executionInfo":{"status":"ok","timestamp":1672205558901,"user_tz":-300,"elapsed":1346,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"56ea961a-4283-433e-f075-07ecbbfd9a89"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[WordList(['The', 'cute', 'little']),\n"," WordList(['cute', 'little', 'boy']),\n"," WordList(['little', 'boy', 'is']),\n"," WordList(['boy', 'is', 'playing']),\n"," WordList(['is', 'playing', 'with']),\n"," WordList(['playing', 'with', 'the']),\n"," WordList(['with', 'the', 'kitten'])]"]},"metadata":{},"execution_count":20}]}]}