{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Named Entity Recognition (NER)\n","</font></b></h1>"],"metadata":{"id":"g30UjW7xCnPy"}},{"cell_type":"markdown","source":["<h2>\n","<b>\n","\n","<ul>\n","<font color = 'brown green'>\n","\n","<li>\n","NER is the process of extracting important entities, such as person names, place\n","names, and organization names, from some given text. These are usually not present in dictionaries. So, we need to treat them differently.\n","</li><br>\n","\n","<li>\n","The main objective of this process is to identify the named entities (such as proper nouns) and map them to categories, which are already defined.\n","</li><br>\n","\n","<li>\n","For example, categories might include names of people, places, and so on.\n","</li><br>\n","\n","<li>\n","NER has found use in many NLP tasks, including assigning tags to news articles,\n","search algorithms, and more.\n","</li><br>\n","\n","<li>\n","NER can analyze a news article and extract the major people, organizations, and places discussed in it and assign them as tags for new articles.\n","</li><br>\n","\n","</ul>\n","</b>\n","</h2>"],"metadata":{"id":"-0CaUy_wDA2e"}},{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Exercise: Treating Named Entities\n","</font></b></h1>"],"metadata":{"id":"ldvLA_eWQhxF"}},{"cell_type":"markdown","source":["In this exercise, we will find the named entities in a given sentence.\n","<br><br>\n","\n","\"We are reading a book published by Packt which is based out of Birmingham.\""],"metadata":{"id":"MJoItc_YRau9"}},{"cell_type":"markdown","source":["1. Open a Jupyter or colab Notebook."],"metadata":{"id":"whNrRPnxRlaI"}},{"cell_type":"markdown","source":["2. Insert a new cell and add the following code to import the necessary libraries:"],"metadata":{"id":"FKvZiaxZRro_"}},{"cell_type":"code","source":["from nltk import download\n","from nltk import pos_tag\n","from nltk import ne_chunk\n","from nltk import word_tokenize\n","download(['punkt','averaged_perceptron_tagger','stopwords'])\n","download('maxent_ne_chunker')\n","download('words')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1iMFwJXlQfXU","executionInfo":{"status":"ok","timestamp":1671720869371,"user_tz":-300,"elapsed":909,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"10bbc52c-b870-4e6a-d5a4-694b3ab6b7a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["3. Declare the **sentence** variable and assign it a string."],"metadata":{"id":"CT9s0_pdRt3K"}},{"cell_type":"code","source":["sentence = \"We are reading a book published by Packt which is based out of Birmingham.\""],"metadata":{"id":"q1PXKY5CRyke"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. To find the named entities from the preceding text, insert a new cell and add the following code:"],"metadata":{"id":"C_5iRTy6R1dD"}},{"cell_type":"code","source":["def get_ner(text):\n","\n","  i = ne_chunk(pos_tag(word_tokenize(text)), binary = True)\n","  return [a for a in i if len(a) == 1]\n","\n","get_ner(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F6Jw_mTiR7hO","executionInfo":{"status":"ok","timestamp":1671720881225,"user_tz":-300,"elapsed":13,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"2563e8d9-f8bc-4026-9c8e-95f7acb8912b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Tree('NE', [('Packt', 'NNP')]), Tree('NE', [('Birmingham', 'NNP')])]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["We can see that the code identifies the named entities **\"Packt\"** and **\"Birmingham\"** and maps them to an already-defined category, **\"NNP.\"**"],"metadata":{"id":"bAaYk1CVSEgR"}}]}