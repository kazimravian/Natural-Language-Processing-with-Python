{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<h1><b><font color = 'brown'>\n","Preprocessing of Raw Text\n","</font></b></h1>"],"metadata":{"id":"g30UjW7xCnPy"}},{"cell_type":"markdown","source":["<h2>\n","<b>\n","\n","<ul>\n","<font color = 'brown green'>\n","\n","<li>\n","We have a text corpus that is in an improper format. In this activity, we will perform all the preprocessing steps that were discussed earlier to get some meaning out of the text.\n","</li><br>\n","\n","</ul>\n","</b>\n","</h2>"],"metadata":{"id":"-0CaUy_wDA2e"}},{"cell_type":"markdown","source":["1. Open a Jupyter or Colab Notebook."],"metadata":{"id":"3deMksEiPD9t"}},{"cell_type":"markdown","source":["2. Insert a new cell and add the following code to import the necessary libraries:"],"metadata":{"id":"i3vsexz_PIFH"}},{"cell_type":"code","source":["#!pip install autocorrect"],"metadata":{"id":"r4Xoaan8UJkp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk import download\n","download('stopwords')\n","download('wordnet')\n","download('punkt')\n","download('averaged_perceptron_tagger')\n","download('omw-1.4')\n","\n","from nltk import word_tokenize\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from autocorrect import Speller\n","from nltk.wsd import lesk\n","from nltk.tokenize import sent_tokenize\n","from nltk import stem, pos_tag\n","import string"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hghHb3uXPMDh","executionInfo":{"status":"ok","timestamp":1672063965417,"user_tz":-300,"elapsed":9,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"320bdd62-0283-4452-bdb0-ab3e25dab9ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}]},{"cell_type":"markdown","source":["3. Read the content of **file.txt** and store it in a variable named **sentence**."],"metadata":{"id":"KmAD_D9NPMr8"}},{"cell_type":"code","source":["sentence = open('/content/drive/MyDrive/NLP/intro_to_nlp/file.txt', 'r').read()\n","sentence"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"6Ct1LTLvPjsL","executionInfo":{"status":"ok","timestamp":1672060795360,"user_tz":-300,"elapsed":3335,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"6d80ea74-2679-4235-98fe-d0bc2d7b9d42"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'The reader of this course should have a basic knowledge of the Python programming lenguage.\\nHe/she must have knowldge of data types in Python.He should be able to write functions,\\n and also have the ability to import and use libraries and packages in Python. Familiarity\\n with basic linguistics and probability is assumed although not required to fully\\n complete this course.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["4. Apply tokenization on the given text corpus."],"metadata":{"id":"N6rhxx3rPkUu"}},{"cell_type":"code","source":["words = word_tokenize(sentence)"],"metadata":{"id":"MHtPquznPrFn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. To print the list of tokens, insert a new cell and add the following code:"],"metadata":{"id":"paOQXn2sPspa"}},{"cell_type":"code","source":["words[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OIdQFTkSP0db","executionInfo":{"status":"ok","timestamp":1672060809353,"user_tz":-300,"elapsed":11,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"3e8830cd-fc55-4c21-ec7f-e6d3dfcb05f9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The',\n"," 'reader',\n"," 'of',\n"," 'this',\n"," 'course',\n"," 'should',\n"," 'have',\n"," 'a',\n"," 'basic',\n"," 'knowledge',\n"," 'of',\n"," 'the',\n"," 'Python',\n"," 'programming',\n"," 'lenguage',\n"," '.',\n"," 'He/she',\n"," 'must',\n"," 'have',\n"," 'knowldge']"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["6. To perform spelling correction in our given text corpus, loop through each token and correct the tokens that are wrongly spelled."],"metadata":{"id":"B7PZLRZtP1BT"}},{"cell_type":"code","source":["spell = Speller(lang = 'en')\n","\n","def correct_sentence(words):\n","  corrected_sentence = \"\"\n","  corrected_words_list = []\n","  for wd in words:\n","    if wd not in string.punctuation:\n","      wd_c = spell(wd)\n","      if wd_c != wd:\n","        print(wd + \" has been corrected to: \" + wd_c)\n","        corrected_sentence = corrected_sentence + \" \" + wd_c\n","        corrected_words_list.append(wd_c)\n","      else:\n","        corrected_sentence = corrected_sentence + \" \" + wd\n","        corrected_words_list.append(wd)\n","    else:\n","      corrected_sentence = corrected_sentence + wd\n","      corrected_words_list.append(wd)\n","\n","  return corrected_sentence, corrected_words_list\n","\n","corrected_sentence, corrected_words_list = correct_sentence(words)     "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kR7iFwFNP803","executionInfo":{"status":"ok","timestamp":1672060815297,"user_tz":-300,"elapsed":39,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"96950281-63c4-465d-8687-f16df41157f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["lenguage has been corrected to: language\n","knowldge has been corrected to: knowledge\n"]}]},{"cell_type":"markdown","source":["7. To print the corrected text corpus, add a new cell and type the following code:"],"metadata":{"id":"n917krI8QRwT"}},{"cell_type":"code","source":["corrected_sentence"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"GxN-pwjlQTM7","executionInfo":{"status":"ok","timestamp":1672060820067,"user_tz":-300,"elapsed":15,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"10bd8b49-36dd-4413-d15e-cea71ecb43cd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' The reader of this course should have a basic knowledge of the Python programming language. He/she must have knowledge of data types in Python.He should be able to write functions, and also have the ability to import and use libraries and packages in Python. Familiarity with basic linguistics and probability is assumed although not required to fully complete this course.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["8. To print a list of the initial 20 tokens of the corrected words, insert a new cell and add the following code:"],"metadata":{"id":"z8ULB7mzQUoo"}},{"cell_type":"code","source":["corrected_words_list[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPmPJFyCQaYo","executionInfo":{"status":"ok","timestamp":1672060830310,"user_tz":-300,"elapsed":1316,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"3fac63c9-787f-4e14-8f59-089908490f2d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The',\n"," 'reader',\n"," 'of',\n"," 'this',\n"," 'course',\n"," 'should',\n"," 'have',\n"," 'a',\n"," 'basic',\n"," 'knowledge',\n"," 'of',\n"," 'the',\n"," 'Python',\n"," 'programming',\n"," 'language',\n"," '.',\n"," 'He/she',\n"," 'must',\n"," 'have',\n"," 'knowledge']"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["9. To add a **PoS** tag to all the corrected words in the list, insert a new cell and add the following code:"],"metadata":{"id":"-vG9V7NZQb9J"}},{"cell_type":"code","source":["pos_tag(corrected_words_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CCeNoBV0QlP5","executionInfo":{"status":"ok","timestamp":1672060833847,"user_tz":-300,"elapsed":760,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"45221eb6-e295-4843-af62-701dd997e792"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('The', 'DT'),\n"," ('reader', 'NN'),\n"," ('of', 'IN'),\n"," ('this', 'DT'),\n"," ('course', 'NN'),\n"," ('should', 'MD'),\n"," ('have', 'VB'),\n"," ('a', 'DT'),\n"," ('basic', 'JJ'),\n"," ('knowledge', 'NN'),\n"," ('of', 'IN'),\n"," ('the', 'DT'),\n"," ('Python', 'NNP'),\n"," ('programming', 'NN'),\n"," ('language', 'NN'),\n"," ('.', '.'),\n"," ('He/she', 'NNP'),\n"," ('must', 'MD'),\n"," ('have', 'VB'),\n"," ('knowledge', 'NN'),\n"," ('of', 'IN'),\n"," ('data', 'NNS'),\n"," ('types', 'NNS'),\n"," ('in', 'IN'),\n"," ('Python.He', 'NNP'),\n"," ('should', 'MD'),\n"," ('be', 'VB'),\n"," ('able', 'JJ'),\n"," ('to', 'TO'),\n"," ('write', 'VB'),\n"," ('functions', 'NNS'),\n"," (',', ','),\n"," ('and', 'CC'),\n"," ('also', 'RB'),\n"," ('have', 'VBP'),\n"," ('the', 'DT'),\n"," ('ability', 'NN'),\n"," ('to', 'TO'),\n"," ('import', 'NN'),\n"," ('and', 'CC'),\n"," ('use', 'NN'),\n"," ('libraries', 'NNS'),\n"," ('and', 'CC'),\n"," ('packages', 'NNS'),\n"," ('in', 'IN'),\n"," ('Python', 'NNP'),\n"," ('.', '.'),\n"," ('Familiarity', 'NN'),\n"," ('with', 'IN'),\n"," ('basic', 'JJ'),\n"," ('linguistics', 'NNS'),\n"," ('and', 'CC'),\n"," ('probability', 'NN'),\n"," ('is', 'VBZ'),\n"," ('assumed', 'VBN'),\n"," ('although', 'IN'),\n"," ('not', 'RB'),\n"," ('required', 'VBN'),\n"," ('to', 'TO'),\n"," ('fully', 'RB'),\n"," ('complete', 'VB'),\n"," ('this', 'DT'),\n"," ('course', 'NN'),\n"," ('.', '.')]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["10. To remove the stop words, insert a new cell and add the following code:"],"metadata":{"id":"Cu7Rg-yRQnEx"}},{"cell_type":"code","source":["stop_words = stopwords.words('english')\n","\n","def remove_stop_words(word_list):\n","  corrected_word_list_without_stopwords = []\n","  for wd in word_list:\n","    if wd not in stop_words:\n","      corrected_word_list_without_stopwords.append(wd)\n","  \n","  return corrected_word_list_without_stopwords \n","\n","corrected_word_list_without_stopwords = remove_stop_words(corrected_words_list)\n","\n","corrected_word_list_without_stopwords[:20]    "],"metadata":{"id":"d-P1SLXIQx-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672062344798,"user_tz":-300,"elapsed":12,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"81a6b94e-89b8-4ccb-a0ca-912aff0ad5c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The',\n"," 'reader',\n"," 'course',\n"," 'basic',\n"," 'knowledge',\n"," 'Python',\n"," 'programming',\n"," 'language',\n"," '.',\n"," 'He/she',\n"," 'must',\n"," 'knowledge',\n"," 'data',\n"," 'types',\n"," 'Python.He',\n"," 'able',\n"," 'write',\n"," 'functions',\n"," ',',\n"," 'also']"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["11. Apply the stemming process, and then insert a new cell and add the\n","following code:"],"metadata":{"id":"Dg8HQKN4QyiW"}},{"cell_type":"code","source":["stemmer = stem.PorterStemmer()\n","\n","def get_stems(word_list):\n","  corrected_word_list_without_stopwords_stemmed = []\n","  for wd in word_list:\n","    corrected_word_list_without_stopwords_stemmed.append(stemmer.stem(wd))\n","\n","  return corrected_word_list_without_stopwords_stemmed\n","\n","corrected_word_list_without_stopwords_stemmed = get_stems(corrected_word_list_without_stopwords)\n","\n","corrected_word_list_without_stopwords_stemmed[:20]  "],"metadata":{"id":"LCP-yuSGQ5D1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672062976806,"user_tz":-300,"elapsed":10,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"3919d70f-1782-48ba-e336-b8eb339b12b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['the',\n"," 'reader',\n"," 'cours',\n"," 'basic',\n"," 'knowledg',\n"," 'python',\n"," 'program',\n"," 'languag',\n"," '.',\n"," 'he/sh',\n"," 'must',\n"," 'knowledg',\n"," 'data',\n"," 'type',\n"," 'python.h',\n"," 'abl',\n"," 'write',\n"," 'function',\n"," ',',\n"," 'also']"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["12. To apply the lemmatization process to the corrected word list, insert a new cell and add the following code:"],"metadata":{"id":"G3rifOo1Q5ye"}},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","\n","def get_lemma(word_list):\n","  corrected_word_list_without_stopwords_lemmatized = []\n","  for wd in word_list:\n","    corrected_word_list_without_stopwords_lemmatized.append(lemmatizer.lemmatize(wd))\n","  return corrected_word_list_without_stopwords_lemmatized\n","\n","corrected_word_list_without_stopwords_lemmatized = get_lemma(corrected_word_list_without_stopwords_stemmed)\n","\n","corrected_word_list_without_stopwords_lemmatized[:20]"],"metadata":{"id":"SQy2TB7rRCQv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672064344911,"user_tz":-300,"elapsed":8,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"e7a2c011-1dff-4789-8532-b49d13ec1232"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['the',\n"," 'reader',\n"," 'cours',\n"," 'basic',\n"," 'knowledg',\n"," 'python',\n"," 'program',\n"," 'languag',\n"," '.',\n"," 'he/sh',\n"," 'must',\n"," 'knowledg',\n"," 'data',\n"," 'type',\n"," 'python.h',\n"," 'abl',\n"," 'write',\n"," 'function',\n"," ',',\n"," 'also']"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["13. To detect the sentence boundary in the given text corpus, use the **sent_\n","tokenize()** method."],"metadata":{"id":"Cr6St9ahRC-w"}},{"cell_type":"code","source":["sent_tokenize(corrected_sentence)"],"metadata":{"id":"vp3tPLKqRaRX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672064360390,"user_tz":-300,"elapsed":558,"user":{"displayName":"Kazim Ali","userId":"17788360296826308952"}},"outputId":"55965052-973e-494e-d83e-3ee5f96c3c76"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' The reader of this course should have a basic knowledge of the Python programming language.',\n"," 'He/she must have knowledge of data types in Python.He should be able to write functions, and also have the ability to import and use libraries and packages in Python.',\n"," 'Familiarity with basic linguistics and probability is assumed although not required to fully complete this course.']"]},"metadata":{},"execution_count":41}]}]}